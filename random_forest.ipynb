{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "550389b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold, KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3815e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_preprocessed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d987ec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 8000, Features: 5\n"
     ]
    }
   ],
   "source": [
    "inputs = df.drop([\"Recovery Index\", \"Id\"], axis=1)\n",
    "target = df[\"Recovery Index\"]\n",
    "X = inputs.values\n",
    "y = target.values\n",
    "print(f\"Samples: {X.shape[0]}, Features: {X.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df156be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomizedSearchCV on 8000 samples, 5 features\n",
      "Fitting 30 folds for each of 40 candidates, totalling 1200 fits\n",
      "RandomizedSearchCV done in 217.3s\n",
      "Best params: {'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 0.6, 'max_depth': 30, 'bootstrap': True}\n",
      "Best CV RMSE (search): 2.1899\n",
      "OOF metrics -> RMSE: 2.1889, MSE: 4.7913, MAE: 1.7371\n",
      "Final RandomForest trained on full dataset\n",
      "OOB R^2: 0.9870\n",
      "Saved rf_tuned_predictions_vs_actual.csv (first 5 rows):\n",
      "     Id  Actual_Recovery_Index  Predicted_Recovery_Index     Error  \\\n",
      "0  9255                     36                 34.737555 -1.262445   \n",
      "1  1562                     25                 25.347348  0.347348   \n",
      "2  1671                     59                 58.679904 -0.320096   \n",
      "3  6088                     22                 21.425181 -0.574819   \n",
      "4  6670                     40                 40.257802  0.257802   \n",
      "\n",
      "   Absolute_Error  \n",
      "0        1.262445  \n",
      "1        0.347348  \n",
      "2        0.320096  \n",
      "3        0.574819  \n",
      "4        0.257802  \n",
      "Full-data metrics -> RMSE: 1.7296, MSE: 2.9916, MAE: 1.3700\n",
      "Saved tuned random forest to random_forest_tuned.joblib\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running RandomizedSearchCV on {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "\n",
    "# 1) broader randomized search space for RF\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 300, 500],\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"max_features\": [\"sqrt\", 0.6, 0.8],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"bootstrap\": [True]   \n",
    "}\n",
    "\n",
    "# 2) use RepeatedKFold for more stable CV during search\n",
    "search_cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "rfr_base = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "rnd = RandomizedSearchCV(\n",
    "    rfr_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=40,                     \n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=search_cv,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "rnd.fit(X, y)\n",
    "print(f\"RandomizedSearchCV done in {time.time() - start:.1f}s\")\n",
    "best_params = rnd.best_params_\n",
    "best_cv_rmse = np.sqrt(-rnd.best_score_)\n",
    "print(\"Best params:\", best_params)\n",
    "print(f\"Best CV RMSE (search): {best_cv_rmse:.4f}\")\n",
    "\n",
    "# 3) Out‑of‑fold (OOF) predictions with a plain KFold for unbiased estimate\n",
    "oof_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "best_model = rnd.best_estimator_\n",
    "oof_preds = cross_val_predict(best_model, X, y, cv=oof_cv, n_jobs=-1)\n",
    "mse_oof = mean_squared_error(y, oof_preds)\n",
    "rmse_oof = np.sqrt(mse_oof)\n",
    "mae_oof = mean_absolute_error(y, oof_preds)\n",
    "print(f\"OOF metrics -> RMSE: {rmse_oof:.4f}, MSE: {mse_oof:.4f}, MAE: {mae_oof:.4f}\")\n",
    "\n",
    "# 4) Fit final RandomForest on full data with best params and enable OOB\n",
    "\n",
    "final_params = best_params.copy()\n",
    "final_params.update({\"random_state\": 42, \"n_jobs\": -1, \"oob_score\": True})\n",
    "final_rf = RandomForestRegressor(**final_params)\n",
    "final_rf.fit(X, y)\n",
    "print(\"Final RandomForest trained on full dataset\")\n",
    "\n",
    "\n",
    "if hasattr(final_rf, \"oob_score_\"):\n",
    "    print(f\"OOB R^2: {final_rf.oob_score_:.4f}\")\n",
    "\n",
    "# 5) Predictions on full dataset and save results + model\n",
    "preds = final_rf.predict(X)\n",
    "results_df = pd.DataFrame({\n",
    "    \"Id\": df[\"Id\"] if \"Id\" in df.columns else np.arange(len(y)),\n",
    "    \"Actual_Recovery_Index\": y,\n",
    "    \"Predicted_Recovery_Index\": preds\n",
    "})\n",
    "results_df[\"Error\"] = results_df[\"Predicted_Recovery_Index\"] - results_df[\"Actual_Recovery_Index\"]\n",
    "results_df[\"Absolute_Error\"] = results_df[\"Error\"].abs()\n",
    "results_df.to_csv(\"rf_tuned_predictions_vs_actual.csv\", index=False)\n",
    "print(\"Saved rf_tuned_predictions_vs_actual.csv (first 5 rows):\")\n",
    "print(results_df.head(5))\n",
    "\n",
    "mse_full = mean_squared_error(results_df[\"Actual_Recovery_Index\"], results_df[\"Predicted_Recovery_Index\"])\n",
    "rmse_full = np.sqrt(mse_full)\n",
    "mae_full = mean_absolute_error(results_df[\"Actual_Recovery_Index\"], results_df[\"Predicted_Recovery_Index\"])\n",
    "print(f\"Full-data metrics -> RMSE: {rmse_full:.4f}, MSE: {mse_full:.4f}, MAE: {mae_full:.4f}\")\n",
    "\n",
    "joblib.dump({\"model\": final_rf}, \"random_forest_tuned.joblib\", compress=3)\n",
    "print(\"Saved tuned random forest to random_forest_tuned.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f30760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b939ebd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
