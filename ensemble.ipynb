{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e97315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Actual Data Loaded ---\n",
      "Train samples: 8000, Test samples: 2000\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from itertools import combinations\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import RidgeCV, ElasticNetCV\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "# --- Load data (expects train.csv and test.csv in working dir) ---\n",
    "try:\n",
    "    train_df = pd.read_csv(\"train.csv\")\n",
    "    test_df = pd.read_csv(\"test.csv\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"train.csv or test.csv not found in working directory\")\n",
    "\n",
    "test_ids = test_df[\"Id\"]\n",
    "X = train_df.drop([\"Id\", \"Recovery Index\"], axis=1).copy()\n",
    "y = train_df[\"Recovery Index\"].values.ravel()\n",
    "X_test = test_df.drop(\"Id\", axis=1).copy()\n",
    "\n",
    "# --- Simple preprocessing and light feature engineering ---\n",
    "def fe(df):\n",
    "    # map lifestyle to binary and create a few interpretable combos\n",
    "    df = df.copy()\n",
    "    df[\"Lifestyle Activities\"] = df[\"Lifestyle Activities\"].fillna(\"No\")\n",
    "    df[\"Lifestyle_Active\"] = (df[\"Lifestyle Activities\"] == \"Yes\").astype(int)\n",
    "    df = df.drop(\"Lifestyle Activities\", axis=1)\n",
    "    T = df[\"Therapy Hours\"]\n",
    "    H = df[\"Initial Health Score\"]\n",
    "    S = df[\"Average Sleep Hours\"]\n",
    "    F = df[\"Follow-Up Sessions\"]\n",
    "    eps = 1e-6\n",
    "    df[\"Therapy_Per_FollowUp\"] = T / (F + eps)\n",
    "    df[\"Sleep_Health_Product\"] = S * H\n",
    "    df[\"Combined_Treatment_Hours\"] = T + F\n",
    "    df[\"Health_Per_Sleep\"] = H / (S + eps)\n",
    "    df[\"Therapy_Health_Product\"] = T * H\n",
    "    return df\n",
    "\n",
    "X = fe(X)\n",
    "X_test = fe(X_test)\n",
    "# align columns to avoid mismatch\n",
    "X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# --- Impute numeric missing values using median (fit on train) ---\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_imp = pd.DataFrame(imp.fit_transform(X), columns=X.columns, index=X.index)\n",
    "X_test_imp = pd.DataFrame(imp.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# --- Optionally add limited pairwise interactions among top k features (keeps model compact) ---\n",
    "k_top = min(6, X_imp.shape[1])\n",
    "sel = SelectKBest(f_regression, k=k_top).fit(X_imp.values, y)\n",
    "top_cols = [X_imp.columns[i] for i in sel.get_support(indices=True)]\n",
    "for a, b in combinations(top_cols, 2):\n",
    "    name = f\"{a}__x__{b}\"\n",
    "    X_imp[name] = X_imp[a] * X_imp[b]\n",
    "    X_test_imp[name] = X_test_imp[a] * X_test_imp[b]\n",
    "\n",
    "# --- Model pipelines (small, clear) ---\n",
    "n_feats = X_imp.shape[1]\n",
    "k_select = min(12, max(3, n_feats))\n",
    "models = {\n",
    "    \"ridge\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"select\", SelectKBest(score_func=f_regression, k=k_select)),\n",
    "        (\"ridge\", RidgeCV(alphas=[0.01, 0.1, 1.0], cv=5))\n",
    "    ]),\n",
    "    \"elasticnet\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"select\", SelectKBest(score_func=f_regression, k=k_select)),\n",
    "        (\"en\", ElasticNetCV(l1_ratio=[0.1,0.5,0.9], alphas=[0.01,0.1,1.0], cv=5, max_iter=5000))\n",
    "    ]),\n",
    "    \"hgb\": Pipeline([\n",
    "        (\"hgb\", HistGradientBoostingRegressor(random_state=42, max_iter=800, learning_rate=0.05))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# --- OOF predictions (partitioning CV required) ---\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "oof = {}\n",
    "rmse = {}\n",
    "start = time.time()\n",
    "for name, pipe in models.items():\n",
    "    print(f\"OOF {name} ...\", end=\" \")\n",
    "    preds_oof = cross_val_predict(pipe, X_imp.values, y, cv=cv, n_jobs=-1, method=\"predict\")\n",
    "    oof[name] = preds_oof\n",
    "    rmse[name] = np.sqrt(mean_squared_error(y, preds_oof))\n",
    "    print(f\"RMSE={rmse[name]:.4f}\")\n",
    "print(\"OOF done in\", time.time()-start, \"s\")\n",
    "\n",
    "# --- Stacking meta (train on OOF preds + a few top original features) ---\n",
    "oof_matrix = np.vstack([oof[m] for m in oof]).T\n",
    "meta_X = np.hstack([oof_matrix, X_imp[top_cols].values])\n",
    "meta = RidgeCV(alphas=[0.01, 0.1, 1.0], cv=5)\n",
    "meta.fit(meta_X, y)\n",
    "print(\"Meta OOF RMSE:\", np.sqrt(mean_squared_error(y, meta.predict(meta_X))))\n",
    "\n",
    "# --- Fit base models on full data and predict test set ---\n",
    "test_preds = []\n",
    "for name, pipe in models.items():\n",
    "    pipe.fit(X_imp.values, y)\n",
    "    test_preds.append(pipe.predict(X_test_imp.values))\n",
    "test_matrix = np.vstack(test_preds).T\n",
    "\n",
    "# meta prediction on test (use same augmentation)\n",
    "meta_test_X = np.hstack([test_matrix, X_test_imp[top_cols].values])\n",
    "pred_stack = meta.predict(meta_test_X)\n",
    "\n",
    "# --- Weighted fallback and small blend for stability ---\n",
    "rmse_vals = np.array([rmse[m] for m in [\"ridge\",\"elasticnet\",\"hgb\"]])\n",
    "w = 1.0 / (rmse_vals**2 + 1e-12)\n",
    "w = w / w.sum()\n",
    "pred_weighted = (test_matrix * w).sum(axis=1)\n",
    "\n",
    "final_pred = 0.9 * pred_stack + 0.1 * pred_weighted\n",
    "# keep within observed target range and round for submission\n",
    "ymin, ymax = y.min(), y.max()\n",
    "final_pred = np.clip(final_pred, ymin, ymax)\n",
    "final_int = np.rint(final_pred).astype(int)\n",
    "\n",
    "# --- Save submission and models ---\n",
    "sub = pd.DataFrame({\"Id\": test_ids, \"Recovery Index\": final_int})\n",
    "sub.to_csv(\"submission_ensemble_improved.csv\", index=False)\n",
    "joblib.dump({\"models\": models, \"meta\": meta, \"weights\": w, \"rmse\": rmse, \"top_cols\": top_cols},\n",
    "            \"ensemble_improved.joblib\", compress=3)\n",
    "print(\"Saved submission_ensemble_improved.csv and ensemble_compact.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0702a667",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
